{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "116e6d02-b3ea-4c9a-9f12-40da794be5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cdsapi\n",
    "import os\n",
    "import zipfile\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "from calendar import monthrange\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from Func_extr import extract_infos\n",
    "\n",
    "##### EXTRACCIÓN DE COPERMICUS\n",
    "\n",
    "def preprocesarDataFrame(df):\n",
    "    df = df[['valid_time', 'latitude', 'longitude', 'tp', 'skt', 'e', 'ro', 'sf',\n",
    "         'swvl1', 'swvl2', 'swvl3', 'swvl4', 'cvh', 'cvl', 'tvh', 'tvl']]\n",
    "    df = df.rename(columns={\n",
    "        'valid_time': 'date',\n",
    "        'tp': 'total_precipitation',\n",
    "        'skt': 'skin_temperature',\n",
    "        'e': 'evaporation',\n",
    "        'ro': 'runoff',\n",
    "        'sf': 'snowfall',\n",
    "        'swvl1': 'soil_water_l1',\n",
    "        'swvl2': 'soil_water_l2',\n",
    "        'swvl3': 'soil_water_l3',\n",
    "        'swvl4': 'soil_water_l4',\n",
    "        'cvh': 'high_vegetation_cover',\n",
    "        'cvl': 'low_vegetation_cover',\n",
    "        'tvh': 'type_high_vegetation',\n",
    "        'tvl': 'type_low_vegetation'\n",
    "    })\n",
    "    # Convertir la columna 'date' a formato de fecha\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "    # Realizar las agregaciones\n",
    "    agg_funcs = {\n",
    "        'total_precipitation': 'sum',\n",
    "        'skin_temperature': 'mean',\n",
    "        'evaporation': 'sum',\n",
    "        'runoff': 'sum',\n",
    "        'snowfall': 'sum',\n",
    "        'soil_water_l1': 'sum',\n",
    "        'soil_water_l2': 'sum',\n",
    "        'soil_water_l3': 'sum',\n",
    "        'soil_water_l4': 'sum',\n",
    "        'high_vegetation_cover': 'mean',\n",
    "        'low_vegetation_cover': 'mean',\n",
    "        'type_high_vegetation': lambda x: x.mode()[0] if not x.mode().empty else np.nan,\n",
    "        'type_low_vegetation': lambda x: x.mode()[0] if not x.mode().empty else np.nan\n",
    "    }\n",
    "    df = df.groupby(['latitude', 'longitude', 'date']).agg(agg_funcs).reset_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def downloadMesCopernicus (days,year, month):\n",
    "    dataset = \"reanalysis-era5-single-levels\"\n",
    "    request = {\n",
    "    'product_type': ['ensemble_mean'],\n",
    "    'variable': ['total_precipitation', 'skin_temperature', 'evaporation', 'runoff', 'snowfall', 'volumetric_soil_water_layer_1', 'volumetric_soil_water_layer_2', 'volumetric_soil_water_layer_3', 'volumetric_soil_water_layer_4', 'high_vegetation_cover', 'low_vegetation_cover', 'type_of_high_vegetation', 'type_of_low_vegetation'],\n",
    "    'year': [str(year)],\n",
    "    'month': [str(month)],\n",
    "    'day': days,\n",
    "    'time': ['00:00', '03:00', '06:00', '09:00', '12:00', '15:00', '18:00', '21:00'],\n",
    "    'data_format': 'netcdf',\n",
    "    'download_format': 'unarchived',\n",
    "    'area': [40.5425, -2.255, 38.1739, 0.5665] ##Cuenca hidrográfica del Jucar +/-\n",
    "    }\n",
    "    client = cdsapi.Client()\n",
    "    file_name = client.retrieve(dataset, request).download()\n",
    "\n",
    "    return file_name\n",
    "    \n",
    "def procesarZip(zip_file_name):\n",
    "    dataFrames = []\n",
    "    with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
    "        # Listar los archivos en el ZIP\n",
    "        archivos = zip_ref.namelist()\n",
    "        for archivo_nc in archivos: \n",
    "            # Extraer el archivo 'instant'\n",
    "            zip_ref.extract(archivo_nc)\n",
    "            print(f\"Archivo '{archivo_nc}' extraído.\")\n",
    "            ds = xr.open_dataset(archivo_nc)\n",
    "            df = ds.to_dataframe().reset_index()\n",
    "            dataFrames.append (df)\n",
    "            ds.close()\n",
    "            os.remove(archivo_nc)\n",
    "    df1 = dataFrames[1]\n",
    "    df1 = df1.drop(['latitude', 'longitude', 'valid_time'], axis = 1)\n",
    "    df = pd.concat([dataFrames[0],df1], axis = 1)\n",
    "    df = preprocesarDataFrame(df)\n",
    "    fechaMin = df['date'].min()\n",
    "    fechaMax = df['date'].max()\n",
    "    print(f'Datos de coeprnicus con fechas de {fechaMin} a {fechaMax} descargadas correctamente')\n",
    "    os.remove(zip_file_name)\n",
    "    return df\n",
    "\n",
    "def extraccionCopernicus (days,year, month):\n",
    "    \n",
    "    zip_file_name = downloadMesCopernicus(days,year, month)\n",
    "    print(f\"Archivo descargado: {zip_file_name}\")\n",
    "\n",
    "    df = procesarZip(zip_file_name)\n",
    "    return df\n",
    "\n",
    "def extraerUltimasFechasCopernicus():\n",
    "    conn = sqlite3.connect('aguaCHJucar.db')\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = f'''\n",
    "        SELECT \n",
    "        c.date_id, d.date\n",
    "        FROM df_copernicus c JOIN df_date d ON  c.date_id = d.date_id;\n",
    "    '''\n",
    "    # Ejecutar la consulta\n",
    "    cursor.execute(query)\n",
    "    df_date = pd.read_sql_query(query, conn)\n",
    "    df_date['date'] = pd.to_datetime(df_date['date']).dt.date\n",
    "    ultima_fecha = df_date['date'].max()\n",
    "    return ultima_fecha\n",
    "    \n",
    "def generar_diferencias_mes_a_mes(fecha1 ,fecha2):\n",
    "    \"\"\"\n",
    "    Genera una lista de días, meses y años entre dos fechas mes a mes,\n",
    "    considerando la fecha inicial desde su día específico y el día final.\n",
    "\n",
    "    Parámetros:\n",
    "    - fecha_actual: Fecha inicial en formato datetime.date.\n",
    "    - fecha_futura: Fecha final en formato datetime.date.\n",
    "\n",
    "    Retorno:\n",
    "    - Lista de tuplas (días, año, mes), donde:\n",
    "      - días: lista de strings con los días del mes ('15', '16', ..., '30')\n",
    "      - año: año correspondiente\n",
    "      - mes: mes correspondiente\n",
    "    \"\"\"\n",
    "    diferencias = []\n",
    "    fecha1 = fecha1  + timedelta(days=1)\n",
    "    fecha_inicio = fecha1  \n",
    "\n",
    "    while fecha_inicio <= fecha2:\n",
    "        # Obtener año y mes actuales\n",
    "        year = fecha_inicio.year\n",
    "        month = fecha_inicio.month\n",
    "\n",
    "        # Si estamos en el primer mes, iniciar desde el día específico de la fecha actual\n",
    "        if fecha_inicio == fecha1:\n",
    "            start_day = fecha_inicio.day\n",
    "        else:\n",
    "            start_day = 1\n",
    "        \n",
    "        # Para el último mes (fecha_futura), restringir al día final\n",
    "        if fecha_inicio.month == fecha2.month:\n",
    "            end_day = fecha2.day\n",
    "        else:\n",
    "            # Si no es el último mes, el mes completo\n",
    "            end_day = monthrange(year, month)[1]\n",
    "\n",
    "        # Calcular los días del mes actual, considerando start_day y end_day\n",
    "        days = [f\"{day:02d}\" for day in range(start_day, end_day + 1)]\n",
    "        \n",
    "        # Agregar a la lista de diferencias\n",
    "        diferencias.append((days, year, month))\n",
    "\n",
    "        # Avanzar al siguiente mes\n",
    "        if month == 12:\n",
    "            fecha_inicio = fecha_inicio.replace(year=year + 1, month=1, day=1)\n",
    "        else:\n",
    "            fecha_inicio = fecha_inicio.replace(month=month + 1, day=1)\n",
    "    \n",
    "    return diferencias\n",
    "\n",
    "def fechasActualizarCopernicus():\n",
    "    fecha1 = extraerUltimasFechasCopernicus()\n",
    "    fecha2 = fecha_actual = datetime.now().date()\n",
    "    fechas_new = generar_diferencias_mes_a_mes(fecha1 ,fecha2)\n",
    "    return fechas_new\n",
    "\n",
    "def actualizarTablaCopernicus():\n",
    "    fechas_new = fechasActualizarCopernicus()\n",
    "    dataFrames = []\n",
    "    for i in fechas_new:\n",
    "        days = i[0]\n",
    "        month = i[2]\n",
    "        year = i[1]\n",
    "        df = extraccionCopernicus (days,year, month)\n",
    "        dataFrames.append(df)\n",
    "    df = pd.concat(dataFrames)\n",
    "    return df\n",
    "\n",
    "##### EXTRACCIÓN DE LA CUENCA DEL JUCAR\n",
    "def extraccionRiosCHJ():\n",
    "    url = \"https://aps.chj.es/down/CSV/F2796_Rios_y_Canales_ROEA.zip\"\n",
    "    fecha_inicial = pd.to_datetime(extraerUltimasFechasCopernicus())\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Verificar si la descarga fue exitosa\n",
    "    \n",
    "    # Paso 2: Cargar el contenido del ZIP en memoria\n",
    "    zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "    target_file = \"F2796_D2_Serie día.csv\"\n",
    "    if target_file in zip_file.namelist():\n",
    "        with zip_file.open(target_file) as file:\n",
    "            # Leer el archivo CSV directamente como DataFrame\n",
    "            df_rios_canales = pd.read_csv(file, sep=\";\", encoding=\"latin1\")  # Ajusta el separador y la codificación si es necesario\n",
    "    \n",
    "    else:\n",
    "        print(f\"El archivo '{target_file}' no se encuentra en el ZIP.\")\n",
    "    df_rios_canales = df_rios_canales.rename(columns = {'Cód. CHJ' : 'id_station','Fecha' : 'date','Cantidad (hm³)' : 'quantity_hm3'})\n",
    "    df_rios_canales = df_rios_canales[['id_station', 'date','quantity_hm3']]\n",
    "    df_rios_canales['date'] = pd.to_datetime(df_rios_canales['date'], format='%d-%m-%Y %H:%M:%S')\n",
    "    df_rios_canales = df_rios_canales.dropna()\n",
    "    df_rios_canales['quantity_hm3'] = df_rios_canales['quantity_hm3'].str.replace(',','.').astype('float')\n",
    "    id_stations_list = []\n",
    "    for pixel in range(176,301):\n",
    "        id_stations = extract_infos (pixel)\n",
    "        id_stations['location_id'] = pixel\n",
    "        id_stations_list.append(id_stations)     \n",
    "    id_stations_df = pd.concat(id_stations_list)\n",
    "    df_rios_canales = df_rios_canales[df_rios_canales['date'] > fecha_inicial]\n",
    "    id_stations_df = id_stations_df[['id_station_rios_canales','pixel']].drop_duplicates()\n",
    "    id_stations_df= id_stations_df.rename(columns = {'id_station_rios_canales' : 'id_station'})\n",
    "    df_rios_canales = pd.merge(df_rios_canales, id_stations_df, on = 'id_station')\n",
    "    return df_rios_canales\n",
    "\n",
    "def extraccionEmbalsesCHJ():\n",
    "    url = \"https://aps.chj.es/down/CSV/F2797_Embalses_ROEA.zip\"\n",
    "    fecha_inicial = pd.to_datetime(extraerUltimasFechasCopernicus())\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Verificar si la descarga fue exitosa\n",
    "    \n",
    "    # Paso 2: Cargar el contenido del ZIP en memoria\n",
    "    zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "    target_file = \"F2797_D1_Serie mes.xlsx\"\n",
    "    if target_file in zip_file.namelist():\n",
    "        with zip_file.open(target_file) as file:\n",
    "            # Leer el archivo CSV directamente como DataFrame\n",
    "            df_embalses = pd.read_excel(file)  # Ajusta el separador y la codificación si es necesario\n",
    "    \n",
    "    else:\n",
    "        print(f\"El archivo '{target_file}' no se encuentra en el ZIP.\")\n",
    "    df_embalses = df_embalses.rename(columns = {'Cód. Embalse' : 'id_station','Fecha' : 'date','Volumen (hm³)' : 'quantity_hm3'})\n",
    "    df_embalses = df_embalses[['id_station', 'date','quantity_hm3']]\n",
    "    df_embalses['date'] = pd.to_datetime(df_rios_canales['date'], format='%d-%m-%Y %H:%M:%S')\n",
    "    df_embalses = df_rios_canales.dropna()\n",
    "    df_embalses['quantity_hm3'] = df_embalses['quantity_hm3'].str.replace(',','.').astype('float')\n",
    "    id_stations_list = []\n",
    "    for pixel in range(176,301):\n",
    "        id_stations = extract_infos (pixel)\n",
    "        id_stations['location_id'] = pixel\n",
    "        id_stations_list.append(id_stations)     \n",
    "    id_stations_df = pd.concat(id_stations_list)\n",
    "    df_embalses = df_embalses[df_embalses['date'] > fecha_inicial]\n",
    "    id_stations_df = id_stations_df[['id_station_rios_canales','pixel']].drop_duplicates()\n",
    "    id_stations_df= id_stations_df.rename(columns = {'id_station_embalse' : 'id_station'})\n",
    "    df_embalses = pd.merge(df_embalses, id_stations_df, on = 'id_station')\n",
    "    return df_embalses\n",
    "\n",
    "def preparacionIngesta(df_copernicus, df_rios):\n",
    "    #tabla fechas\n",
    "    df_copernicus['date'] = pd.to_datetime(df_copernicus['date']).drop_duplicates().reset_index(drop = True)\n",
    "    dates1 = df_copernicus['date'].dropna()\n",
    "    df_date1 = pd.DataFrame({'date': dates1})\n",
    "    df_date1['date_id'] = df_date1['date'].dt.strftime('%Y%m%d').astype(int)\n",
    "    \n",
    "    df_rios['date'] = pd.to_datetime(df_rios['date']).drop_duplicates().reset_index(drop = True)\n",
    "    dates2 = df_rios['date'].dropna()\n",
    "    df_date2 = pd.DataFrame({'date': dates2})\n",
    "    df_date2['date_id'] = df_date2['date'].dt.strftime('%Y%m%d').astype(int)\n",
    "    df_date = pd.concat([df_date1, df_date2])\n",
    "    df_date = df_date.drop_duplicates().reset_index(drop = True)\n",
    "    \n",
    "    #tabla df_copernicus\n",
    "    conn = sqlite3.connect('aguaCHJucar.db')\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    query = f'''\n",
    "        SELECT * FROM locations_id WHERE Type == 'Copernicus'\n",
    "            ;\n",
    "    '''\n",
    "    \n",
    "    df_loc = pd.read_sql_query(query, conn)\n",
    "    cursor.execute(query)\n",
    "    conn.close()\n",
    "    \n",
    "    df_copernicus = pd.merge(df_copernicus, df_loc[['latitude', 'longitude','location_id']], on = ['latitude', 'longitude'], how = 'inner')\n",
    "    df_copernicus = pd.merge(df_copernicus, df_date, on = ['date'], how = 'inner')\n",
    "    df_copernicus = df_copernicus.drop(['latitude', 'longitude', 'date'], axis = 1)\n",
    "    \n",
    "    #tabla ríos\n",
    "    df_rios = pd.merge(df_date,df_rios, on = 'date', how = 'left')\n",
    "    df_rios = df_rios[['quantity_hm3','location_id','date_id']]\n",
    "    return df_copernicus, df_rios, df_date\n",
    "\n",
    "def ingesta(df_copernicus, df_rios, df_date):\n",
    "    # Conexión a la base de datos\n",
    "    connection = sqlite3.connect(\"aguaCHJucar.db\")\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    try:\n",
    "        # Inserciones para df_copernicus\n",
    "        for row in df_rios.itertuples(index=False):\n",
    "            cursor.execute(\"\"\"\n",
    "            INSERT OR IGNORE INTO df_copernicus (\n",
    "                location_id, date_id, total_precipitation,\n",
    "                skin_temperature, evaporation, runoff, snowfall,\n",
    "                soil_water_l1, soil_water_l2, soil_water_l3, soil_water_l4,\n",
    "                high_vegetation_cover, low_vegetation_cover,\n",
    "                type_high_vegetation, type_low_vegetation\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", row)\n",
    "    \n",
    "        # Inserciones para df_rios_canales\n",
    "        for row in df_rios.itertuples(index=False):\n",
    "            cursor.execute(\"\"\"\n",
    "            INSERT OR IGNORE INTO df_rios_canales (\n",
    "                quantity_hm3, location_id, date_id\n",
    "            ) VALUES (?, ?, ?)\n",
    "            \"\"\", row)\n",
    "    \n",
    "        # Inserciones para df_date\n",
    "        for row in df_date.itertuples(index=False):\n",
    "            cursor.execute(\"\"\"\n",
    "            INSERT OR IGNORE INTO df_date (\n",
    "                date, date_id\n",
    "            ) VALUES (?, ?)\n",
    "            \"\"\", row)\n",
    "    \n",
    "        # Confirmar todas las inserciones\n",
    "        connection.commit()\n",
    "    \n",
    "    except sqlite3.Error as e:\n",
    "        # Manejo de errores con rollback en caso de fallo\n",
    "        connection.rollback()\n",
    "        print(f\"Error al insertar registros: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Cerrar la conexión\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef249da-564d-489f-9f27-a98234d6332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copernicus = actualizarTablaCopernicus()\n",
    "df_rios = extraccionRiosCHJ()\n",
    "df_copernicus, df_rios, df_date = preparacionIngesta(df_copernicus, df_rios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ab6c0-1f8c-403f-984a-70f7ce4c20a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
